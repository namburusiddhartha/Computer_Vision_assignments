{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad4fb23-5a5b-49b5-bbb4-f02b125b77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7f840fe-1218-4ce6-8a6d-d6555f2c198e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cce1c07-a288-4328-8faf-2980caaa6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('abc.npy',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70a768b3-cf08-4ace-949a-b7c95a17fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.load('abc.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b71255f7-f2d2-469c-8466-186e89e17620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95be20ce-014e-4d9e-b29c-c8f773d72852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6471bb7-0d55-48bc-a172-487dac0b06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1 , 2 , 3], \n",
    "             [4 , 5,  6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4881852-ad7b-4831-a64b-4d6cce0a5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[7 , 8 , 9], \n",
    "             [10 , 11,  12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab6fb6fa-904e-4bef-82f0-eaa236c0a988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.48528137,  9.89949494, 11.3137085 ],\n",
       "       [ 7.07106781,  8.48528137,  9.89949494],\n",
       "       [ 5.65685425,  7.07106781,  8.48528137]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.spatial.distance.cdist(np.transpose(a), np.transpose(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71f5e4f4-39eb-4102-bd91-25101c9d6444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77e8ec48-b47e-4191-887a-1f0384c3aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(a):\n",
    "    return a - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c1aa050-4161-4c3b-8fb6-de8fb4804aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add (n, b, c):\n",
    "    c = sub(n)\n",
    "    print(c)\n",
    "    return [n * n + b , c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fa844e7-03cf-4de3-8b3c-7ab0d97cbf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "listab = [1 , 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5558421e-1f19-4d41-b6f6-09f9698b4f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "c = np.ones((2,2))\n",
    "d = 1\n",
    "return_values = Parallel(n_jobs=6)(delayed(add)(input , d, c) for input in listab)\n",
    "print(np.array(return_values)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d637f840-c879-4ff7-9a86-010d68568729",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "context has already been set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-22a3ded86cf2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_start_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mset_start_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"spawn\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36mset_start_method\u001b[1;34m(self, method, force)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_start_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_actual_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'context has already been set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_actual_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: context has already been set"
     ]
    }
   ],
   "source": [
    "from multiprocessing import set_start_method\n",
    "set_start_method(\"spawn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32088e27-34d1-4bf0-847a-b0820845ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with multiprocessing.Pool(8) as p:\n",
    "        print(\"threads\")\n",
    "        p.map(add, list)\n",
    "        p.close() # <-- calling close before P.join()\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a069a98-3a6e-4582-b6f0-8e9060d66970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 2, 3], [1, 4, -1], [1, 0, 4], [10, 2, 10], [10, 4, 7], [10, 0, 2]])\n",
    "print(X.shape)\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff27814-d39a-44e2-9b82-f6a77ec0f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xin = np.random.randint(10,size = (4, 3, 3))\n",
    "#Xal = np.reshape(Xin, (4,2))\n",
    "Xal = Xin.reshape(3,-1)\n",
    "\n",
    "print(Xin)\n",
    "print(Xal)\n",
    "#print(Xal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3166b290-ce4d-455b-8f76-e7dffca68adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yin = np.random.randint(10,size = (2, 2))\n",
    "Yin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b481b079-57cf-4f1f-b1c2-1a2dad12038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = scipy.spatial.distance.cdist(Xin, Yin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c5a6ff-5d65-4ecb-b617-23da42d86384",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5]\n",
    "d = [6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c00324-9e1e-43f9-a5f4-ab068516db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "c.append(a)\n",
    "c.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b722970-53a5-43e7-87e9-1761b8d38a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.concatenate(c, axis = 0)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acc9c9c-1162-4713-a277-8e52a941a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b847e0c5-ccf5-4798-8ddd-dd5dc6be382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbf64da-d60f-42f5-9de1-4d9d3e680105",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros((3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a87f87-98b4-4e30-b330-fbe0fdcc6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e9373f-d83f-4d94-a61b-54e2a71bd963",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros((L+1,1))\n",
    "for i in range(L+1):\n",
    "    if i == 0 or i == 1:\n",
    "        weights[i] = 2**(-L)\n",
    "    else:\n",
    "        weights[i] = 2**(i-L-1)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0fe6ef-9a32-46a7-aa3a-9874d6b18d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38cbd8-8654-444b-89f6-c3811620f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 309\n",
    "h = 500\n",
    "L = 3\n",
    "indices_w = []\n",
    "indices_h = []\n",
    "count_x = []\n",
    "for i in range(L + 1):\n",
    "    i_w = [0]\n",
    "    i_h = [0]\n",
    "    count = []\n",
    "    patch_width = math.floor(w / (2**(i)))\n",
    "    patch_height = math.floor(h / (2**(i)))\n",
    "    for j in range(2**(i)):\n",
    "        i_w.append((j + 1) * patch_width)\n",
    "        i_h.append((j + 1) * patch_height)\n",
    "    for j in range(2**(i)):\n",
    "        count.append(j)\n",
    "    count_x.append(count)\n",
    "    indices_w.append(i_w)\n",
    "    indices_h.append(i_h)\n",
    "for i in range(L + 1):\n",
    "    for j in range(2**(i)):\n",
    "        for k in range(2**(i)):\n",
    "            print(indices_h[i][j], indices_h[i][j + 1])\n",
    "            print(indices_w[i][k], indices_w[i][k + 1])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46722d3e-7803-4369-b9b1-b4a94c00a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indices_w)\n",
    "print(indices_w[1][2])\n",
    "print(indices_h)\n",
    "print(count_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e30052-452f-4922-bc2e-f6df7e433c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = np.tile(a, (5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20b55d1-cbfd-440e-9816-a2ca8c802f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34220b79-161e-4109-9b12-5d11e56cc51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.sum(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1293a6-eda1-48a1-98d9-22f80bd0c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.trace(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c50dc-7fe2-4ed7-b887-788c7fb74ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.argmin(np.array([1, 2, 3, 4, 0]))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f423145-4e0c-4eaf-a735-7bc8bc8decdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b528612-24d1-4b68-8165-23cc481ec132",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = np.zeros((8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca06295-30d9-464c-98c2-cce9afe2c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c0207b-ffff-4846-a5bd-3e3de2873b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_from_wordmap_SPM(wordmap, layer_num, dict_size):\n",
    "    '''\n",
    "    Compute histogram of visual words using spatial pyramid matching.\n",
    "\n",
    "    [input]\n",
    "    * wordmap: numpy.ndarray of shape (H,W)\n",
    "    * layer_num: number of spatial pyramid layers\n",
    "    * dict_size: dictionary size K\n",
    "\n",
    "    [output]\n",
    "    * hist_all: numpy.ndarray of shape (K*(4^layer_num-1)/3)\n",
    "    '''\n",
    "    '''\n",
    "    HINTS:\n",
    "    (1) Take care of Weights \n",
    "    (2) Try to build the pyramid in Bottom Up Manner\n",
    "    (3) the output array should first contain the histogram for Level 0 (top most level) , followed by Level 1, and then Level 2.\n",
    "    '''\n",
    "    # ----- TODO -----\n",
    "    h, w = wordmap.shape\n",
    "    L = layer_num - 1\n",
    "    patch_width = math.floor(w / (2**L))\n",
    "    patch_height = math.floor(h / (2**L))\n",
    "    \n",
    "    '''\n",
    "    HINTS:\n",
    "    1.> create an array of size (dict_size, (4**(L + 1) -1)/3) )\n",
    "    2.> pre-compute the starts, ends and weights for the SPM layers L\n",
    "    '''\n",
    "            \n",
    "    # YOUR CODE HERE\n",
    "    hist_all = np.zeros((dict_size, int(((4**(L + 1) -1))/3)))\n",
    "    weights = np.zeros((L+1,1))\n",
    "    for i in range(L + 1):\n",
    "        if i == 0 or i == 1:\n",
    "            weights[i] = 2**(-L)\n",
    "        else:\n",
    "            weights[i] = 2**(i-L-1)\n",
    "    \n",
    "    indices_w = []\n",
    "    indices_h = []\n",
    "    for i in range(L + 1):\n",
    "        i_w = [0]\n",
    "        i_h = [0]\n",
    "        patch_width = math.floor(w / (2**(i)))\n",
    "        patch_height = math.floor(h / (2**(i)))\n",
    "        for j in range(2**(i)):\n",
    "            i_w.append((j + 1) * patch_width)\n",
    "            i_h.append((j + 1) * patch_height)\n",
    "        indices_w.append(i_w)\n",
    "        indices_h.append(i_h)\n",
    "\n",
    "            \n",
    "    # raise NotImplementedError()\n",
    "    '''\n",
    "    HINTS:\n",
    "    1.> Loop over the layers from L to 0\n",
    "    2.> Handle the base case (Layer L) separately and then build over that\n",
    "    3.> Normalize each histogram separately and also normalize the final histogram\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    hist_all_f = []\n",
    "    for i in range(L + 1):\n",
    "        hist_all_temp = []\n",
    "        for j in range(2**(i)):\n",
    "            for k in range(2**(i)):\n",
    "                histo = get_feature_from_wordmap(wordmap[indices_h[i][j]:indices_h[i][j + 1] , indices_w[i][k]:indices_w[i][k + 1]], dict_size)\n",
    "                hist_all_temp.append(get_feature_from_wordmap(wordmap[indices_h[i][j]:indices_h[i][j + 1] , indices_w[i][k]:indices_w[i][k + 1]], dict_size))\n",
    "                plt.figure()\n",
    "                bin_edges = np.arange(dict_size + 1)\n",
    "                plt.bar(bin_edges[:-1], histo, width = 1)\n",
    "                plt.xlim(0, 200)\n",
    "                plt.show() \n",
    "        hist_all_f.append(hist_all_temp)\n",
    "    for i in range(L + 1):\n",
    "        hist_all_f[i] = hist_all_f[i] * weights[i] * (1 / (2**(i) * 2**(i)))\n",
    "    \n",
    "    hist_all = np.concatenate(hist_all_f, axis=0)\n",
    "    hist_all = np.transpose(hist_all).flatten()\n",
    "        \n",
    "    # raise NotImplementedError()\n",
    "    return hist_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b448c25-49f9-4ced-8c56-12a425d88639",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 2\n",
    "for l in range(L, -1, -1):\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3917d86c-2886-4c92-9193-cd1b7f72a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_from_wordmap_SPM(wordmap, layer_num, dict_size):\n",
    "    '''\n",
    "    Compute histogram of visual words using spatial pyramid matching.\n",
    "\n",
    "    [input]\n",
    "    * wordmap: numpy.ndarray of shape (H,W)\n",
    "    * layer_num: number of spatial pyramid layers\n",
    "    * dict_size: dictionary size K\n",
    "\n",
    "    [output]\n",
    "    * hist_all: numpy.ndarray of shape (K*(4^layer_num-1)/3)\n",
    "    '''\n",
    "    '''\n",
    "    HINTS:\n",
    "    (1) Take care of Weights \n",
    "    (2) Try to build the pyramid in Bottom Up Manner\n",
    "    (3) the output array should first contain the histogram for Level 0 (top most level) , followed by Level 1, and then Level 2.\n",
    "    '''\n",
    "    # ----- TODO -----\n",
    "    h, w = wordmap.shape\n",
    "    L = layer_num - 1\n",
    "    n_rows_L = 2**L\n",
    "    n_cols_L = 2**L\n",
    "    patch_width = math.floor(w / (2**L))\n",
    "    patch_height = math.floor(h / (2**L))\n",
    "\n",
    "    '''\n",
    "    HINTS:\n",
    "    1.> create an array of size (dict_size, (4**(L + 1) -1)/3) )\n",
    "    2.> pre-compute the starts, ends and weights for the SPM layers L \n",
    "    '''\n",
    "    weights = np.zeros((L+1,1))\n",
    "    for i in range(L + 1):\n",
    "        if i == 0 or i == 1:\n",
    "            weights[i] = 2**(-L)\n",
    "        else:\n",
    "            weights[i] = 2**(i-L-1)\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    '''\n",
    "    HINTS:\n",
    "    1.> Loop over the layers from L to 0\n",
    "    2.> Handle the base case (Layer L) separately and then build over that\n",
    "    3.> Normalize each histogram separately and also normalize the final histogram\n",
    "    '''\n",
    "    print(dict_size) \n",
    "    output = []\n",
    "    for x in range(L):\n",
    "        y = (L) - x\n",
    "        output_new=[]\n",
    "        hist_new=[]\n",
    "        n_col = 2**y\n",
    "        n_row = 2**y\n",
    "        patch_w = math.floor(w / (2**y))\n",
    "        patch_h = math.floor(h / (2**y)) \n",
    "        stride = int(n_cols_L/n_col) \n",
    "        if y == L:\n",
    "            hist_all_L = np.zeros((n_rows_L, n_cols_L, dict_size))\n",
    "            for i in range(n_rows_L):\n",
    "                for j in range(n_cols_L):\n",
    "                    word_patch = wordmap[i*patch_h: (i+1)*patch_h, j*patch_w : (j+1)*patch_w ]\n",
    "                    hist = get_feature_from_wordmap(word_patch,dict_size)\n",
    "                    hist_all_L[i,j,:] = hist\n",
    "                    output= np.hstack([output, hist*weights[y]])\n",
    "\n",
    "        else:            \n",
    "            for i in range(n_row):\n",
    "                for j in range(n_col):\n",
    "                    hist_new = np.concatenate((hist_all_L[stride*i:stride*(i+1),stride*j:stride*(j+1),: ]))\n",
    "                    hist_new = np.sum(hist_new, axis = 0)\n",
    "                    #print(\"flag histnew: \", hist_new.shape)\n",
    "                    hist_new = np.reshape(hist_new,(-1))\n",
    "                    #hist_new = hist_new.flatten()\n",
    "                    #print(\"flag 1: \", hist_new.shape)\n",
    "                    output_new= np.hstack([output_new, hist_new*weights[y]])\n",
    "                    #print(\"flag 3 :\", output_new.shape)\n",
    "            #print(\"flag 4 :\", output_new.shape)\n",
    "        output= np.hstack([output_new, output])\n",
    "        #print(\"flag 5 :\", output.shape)\n",
    "    \n",
    "    hist_all = output\n",
    "    hist_all = hist_all/np.sum(hist_all)\n",
    "    \n",
    "    return hist_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a80fe1c-7dfa-4c18-bd7e-148b6d4f1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac4c31ce-581a-4e27-9a90-b72eb958142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a, b):\n",
    "    print(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c794396c-e46d-4d10-8dbb-c45235a78fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "with multiprocessing.Pool(4) as p:\n",
    "    #    print(\"threads\")\n",
    "    p.map(add, [6, 7 , 8 , 9 ,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47b05200-0e1e-4a68-8e65-fadd635b06f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "filter weights array has incorrect shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-1d91fdcd6d9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36mconvolve\u001b[1;34m(input, weights, output, mode, cval, origin)\u001b[0m\n\u001b[0;32m    800\u001b[0m     \"\"\"\n\u001b[0;32m    801\u001b[0m     return _correlate_or_convolve(input, weights, output, mode, cval,\n\u001b[1;32m--> 802\u001b[1;33m                                   origin, True)\n\u001b[0m\u001b[0;32m    803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36m_correlate_or_convolve\u001b[1;34m(input, weights, output, mode, cval, origin, convolution)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mwshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mii\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'filter weights array has incorrect shape.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mconvolution\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: filter weights array has incorrect shape."
     ]
    }
   ],
   "source": [
    "a = 2* np.ones((3, 3, 3))\n",
    "b = np.ones((3, 3))\n",
    "import scipy.ndimage\n",
    "L = scipy.ndimage.convolve(a, b, mode = \"constant\")\n",
    "M = np.sum(L, axis = 2)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12ae1b93-42c5-43e1-b986-9e96518c176f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((5,5))\n",
    "c = np.maximum(a, 0)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c625ce2e-3c11-4b27-9f7d-99abdf477888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "[[[11. 12. 13. 14. 15.]\n",
      "  [ 6.  7.  8.  9. 10.]]\n",
      "\n",
      " [[16. 17. 18. 19. 10.]\n",
      "  [21. 22. 23. 24. 25.]]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1., 2., 3., 4., 5.],\n",
    " [6., 7., 8., 9., 10.],\n",
    " [11., 12., 13., 14., 15.],\n",
    " [16., 17., 18., 19., 10.],\n",
    " [21., 22., 23., 24., 25.]])\n",
    "b = np.array([[2,1],[3,4]])\n",
    "print(b.shape)\n",
    "print(a[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6993d1bf-fddd-4c58-a28e-d4be7d1efd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15. 15. 15. 15. 15. 15.]\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((6,5))\n",
    "b = np.array([1, 2, 3, 4, 5])\n",
    "print(a @ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ea26230-4055-4e14-8f2c-25cc1c4415c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485,0.456,0.406])\n",
    "std = np.array([0.229,0.224,0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b95e27e-fdef-4df1-aee8-23c6efaf7e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "209a1110-7e4f-4ee9-80a4-af949ae85f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.tile(mean, (3,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64f38149-c9d0-4de6-b51b-7ae0f63fb148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.406, 0.406, 0.406],\n",
       "       [0.406, 0.406, 0.406],\n",
       "       [0.406, 0.406, 0.406]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7ca0e98-3af5-4799-b75f-b378ec3cf162",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.tile(std, (4,4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8bfc6b97-da71-4743-94eb-57fdceced376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.11790393, 2.03571429, 1.80444444],\n",
       "        [2.11790393, 2.03571429, 1.80444444],\n",
       "        [2.11790393, 2.03571429, 1.80444444]],\n",
       "\n",
       "       [[2.11790393, 2.03571429, 1.80444444],\n",
       "        [2.11790393, 2.03571429, 1.80444444],\n",
       "        [2.11790393, 2.03571429, 1.80444444]],\n",
       "\n",
       "       [[2.11790393, 2.03571429, 1.80444444],\n",
       "        [2.11790393, 2.03571429, 1.80444444],\n",
       "        [2.11790393, 2.03571429, 1.80444444]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.divide(M, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a0a4f7c-340a-4510-9dd8-f7b3f4ec0430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.485, 0.456, 0.406],\n",
       "        [0.485, 0.456, 0.406],\n",
       "        [0.485, 0.456, 0.406]],\n",
       "\n",
       "       [[0.485, 0.456, 0.406],\n",
       "        [0.485, 0.456, 0.406],\n",
       "        [0.485, 0.456, 0.406]],\n",
       "\n",
       "       [[0.485, 0.456, 0.406],\n",
       "        [0.485, 0.456, 0.406],\n",
       "        [0.485, 0.456, 0.406]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "34e491fe-dd31-4324-a31f-87f8187cbe17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "143bd17d-7bcd-4187-9067-c382df85e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "133fc440-b21d-4214-84c3-2afbfaada0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ctr = torch.from_numpy(S)\n",
    "Ctr.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8c918fee-0679-45b8-b183-55dc6dbe7cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eab3b3b5-4f45-4303-8d7e-e790fa0b486b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f8c6734-2e21-44e2-b129-64befb456ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for x in range(7):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53de816a-3d79-45cb-b7b7-a8bc03b33181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = [1,2,3,4,5]\n",
    "N[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48fb59b-24dd-4f7c-8c11-260f90e8464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33c08351-0d86-40ee-9ca2-e47aa390b214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4 5]\n",
      " [1 2 3 4 5]\n",
      " [1 2 3 4 5]\n",
      " [1 2 3 4 5]\n",
      " [1 2 3 4 5]]\n",
      "[4455.  125.  500.  925. 2000.]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "c = np.array([1, 2, 3, 4, 5])\n",
    "b = np.array([[10., 20., 30., 40., 50.],\n",
    " [6., 7., 8., 9., 10.],\n",
    " [11., 12., 13., 14., 15.],\n",
    " [16., 17., 18., 19., 10.],\n",
    " [21., 22., 23., 24., 25.]])\n",
    "dist_test = np.tile(c, (b.shape[0], 1))\n",
    "print(dist_test)\n",
    "distances = np.sum((dist_test - b)**2, axis = 1)\n",
    "print(distances)\n",
    "nearest_image_idx = np.argmin(distances)\n",
    "print(nearest_image_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26371441-64d9-4e69-888c-2a306fcb7966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 4)\n",
      "[ 1  2  3  4  4  5  6 21  7  8  9  2  1  3 55  6  1  2  3  4  4  5  6 21\n",
      "  7  8  9  2  1  3 55  6  1  2  3  4  4  5  6 21  7  8  9  2  1  3 55  6]\n",
      "[ 1  4  7  1  1  4  7  1  1  4  7  1  2  5  8  3  2  5  8  3  2  5  8  3\n",
      "  3  6  9 55  3  6  9 55  3  6  9 55  4 21  2  6  4 21  2  6  4 21  2  6]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 48 into shape (3,3,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-e17f6b51aacb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 48 into shape (3,3,3)"
     ]
    }
   ],
   "source": [
    "A  = np.array([[[1, 2, 3, 4], [4, 5 , 6, 21], [7, 8, 9, 2], [1 , 3, 55, 6]], [[1, 2, 3, 4], [4, 5 , 6, 21], [7, 8, 9, 2], [1 , 3, 55, 6]], [[1, 2, 3, 4], [4, 5 , 6, 21], [7, 8, 9, 2], [1 , 3, 55, 6]]])\n",
    "print(A.shape)\n",
    "B = np.transpose(A, (2, 0, 1))\n",
    "C = A.flatten()\n",
    "print(C)\n",
    "D = B.flatten()\n",
    "print(D)\n",
    "E = D.reshape((3,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94662ad6-fd15-4078-bf46-70e701f8010d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0, 1, 2])\n",
    "c = np.tile(a, (2, 1, 2))\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff30ff08-402c-4fed-9c89-2e67a0900f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(np.transpose(E, (1, 2, 0)).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5f332c-29b2-4e1e-bdd1-1290533f3531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.ndimage\n",
    "\n",
    "def pytorch_conv2d(x, w, b):\n",
    "\n",
    "    x_reorder = np.moveaxis(x, [0, 1, 2], [1, 2, 0])\n",
    "    x_input = np.expand_dims(x_reorder, axis = 0)\n",
    "\n",
    "    x_t = torch.from_numpy(x_input)\n",
    "    w_t = torch.from_numpy(w)\n",
    "\n",
    "    # print(f\"{x_t.shape=}, {w_t.shape=}\")\n",
    "\n",
    "    o_t = F.conv2d(x_t, w_t, padding=1)\n",
    "\n",
    "    output = o_t.numpy()\n",
    "    \n",
    "    output = output[0,:,:,:]\n",
    "\n",
    "    return output\n",
    "\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(10, 10, 2)\n",
    "w = np.random.rand(4, 2, 3, 3)\n",
    "b = np.zeros((4))\n",
    "\n",
    "pyoutput = pytorch_conv2d(x, w, b)\n",
    "cuoutput = multichannel_conv2d(x,w,b)\n",
    "\n",
    "cuoutput = np.moveaxis(cuoutput, [0, 1, 2], [1, 2, 0])\n",
    "\n",
    "diff = pyoutput - cuoutput\n",
    "\n",
    "print(np.sum(diff.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0dc7d1b1-815e-4bc3-9cb4-ae10cdf66ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool2d(x,size):\n",
    "    '''\n",
    "    2D max pooling operation.\n",
    "\n",
    "    [input]\n",
    "    * x: numpy.ndarray of shape (H,W,input_dim)\n",
    "    * size: pooling receptive field\n",
    "\n",
    "    [output]\n",
    "    * y: numpy.ndarray of shape (H/size,W/size,input_dim)\n",
    "    '''\n",
    "    h, w, dims = x.shape\n",
    "    ind1 = np.floor(h/size).astype(int)\n",
    "    ind2 = np.floor(w/size).astype(int)\n",
    "    \n",
    "    pooled_arr = np.zeros((ind1, ind2, dims))\n",
    "    '''\n",
    "    \n",
    "    HINTS:\n",
    "    1.> estimate the shape you need to apply the pooling operation.\n",
    "    2.> We can smart fill the padding with np.nan and then use np.nanmax to select the max (avoiding nan)\n",
    "    3.> We can input the grid (start_x:end_x, start_y:end_y, dim) as smart array indexing to np.nanmax\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    for k in range(dims):\n",
    "        for i in range(ind1):\n",
    "            for j in range(ind2):\n",
    "                pooled_arr[i,j, k] = np.max(x[i*size:(i+1)*size, j*size:(j+1)*size, k]) \n",
    "                print(x[i*size:(i+1)*size, j*size:(j+1)*size, k])\n",
    "                \n",
    "    return pooled_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "23847cf9-fcb2-4f4d-9825-d7fe50ba9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "A  = np.array([[[1, 2, 3, 4], [4, 5 , 6, 21], [7, 8, 9, 2], [1 , 3, 55, 6]], [[1, 2, 3, 4], [4, 5 , 6, 21], [7, 8, 9, 2], [1 , 3, 55, 6]], [[1, 2, 3, 4], [4, 5 , 6, 21], [7, 8, 9, 2], [1 , 3, 55, 66]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bad00bb5-c67a-4377-bcbf-35eb83e898c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [4 5]]\n",
      "[[ 3  4]\n",
      " [ 6 21]]\n",
      "[[7 8]\n",
      " [1 3]]\n",
      "[[ 9  2]\n",
      " [55  6]]\n",
      "[[1 2]\n",
      " [4 5]]\n",
      "[[ 3  4]\n",
      " [ 6 21]]\n",
      "[[7 8]\n",
      " [1 3]]\n",
      "[[ 9  2]\n",
      " [55  6]]\n",
      "[[1 2]\n",
      " [4 5]]\n",
      "[[ 3  4]\n",
      " [ 6 21]]\n",
      "[[7 8]\n",
      " [1 3]]\n",
      "[[ 9  2]\n",
      " [55 66]]\n"
     ]
    }
   ],
   "source": [
    "B = np.transpose(A, (1, 2, 0))\n",
    "C = max_pool2d(B, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "92dde349-4134-4936-b65e-53422bd58e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3)\n",
      "[[ 1  2  3  4]\n",
      " [ 4  5  6 21]\n",
      " [ 7  8  9  2]\n",
      " [ 1  3 55 66]]\n",
      "(4, 4, 3)\n",
      "(3, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "print(C.shape)\n",
    "print(B[:, :, 2])\n",
    "print(B.shape)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "212f0e23-c8a5-435e-8604-1421c79f5100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5. 21.]\n",
      " [ 8. 66.]]\n"
     ]
    }
   ],
   "source": [
    "print(C[:, :, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee581b78-a817-47fb-a981-155d7a70ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    '''\n",
    "    Rectified linear unit.\n",
    "\n",
    "    [input]\n",
    "    * x: numpy.ndarray\n",
    "\n",
    "    [output]\n",
    "    * y: numpy.ndarray\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    y = np.maximum(x, 0)\n",
    "    # raise NotImplementedError()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f4712897-9c7e-43ba-aff6-d563c25a2261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "print(relu(np.array([-1, -1 ,3, 4, 5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084821bc-7a82-4090-b43a-fc178350e4d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4628dca611d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# plt.savefig(filename, pad_inches=0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./dictionary.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mpath_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./data/kitchen/sun_aggjlwcdjsjcaemh.jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def save_wordmap(wordmap):\n",
    "    fig = plt.figure(2)\n",
    "    plt.axis('equal')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(wordmap, cmap=\"rainbow\")\n",
    "    # plt.savefig(filename, pad_inches=0)\n",
    "    \n",
    "dictionary = np.load('./dictionary.npy')\n",
    "\n",
    "path_img = \"./data/kitchen/sun_aggjlwcdjsjcaemh.jpg\"\n",
    "#path_img = \"./data/aquarium/sun_aztvjgubyrgvirup.jpg\"\n",
    "image = io.imread(path_img)\n",
    "plt.figure()\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = image.astype('float')/255\n",
    "wordmap = get_visual_words(image, dictionary)\n",
    "save_wordmap(wordmap)\n",
    "\n",
    "path_img = \"./data/aquarium/sun_ayoehnnyhnartpwz.jpg\"\n",
    "#path_img = \"./data/aquarium/sun_aztvjgubyrgvirup.jpg\"\n",
    "image = io.imread(path_img)\n",
    "plt.figure()\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = image.astype('float')/255\n",
    "wordmap = get_visual_words(image, dictionary)\n",
    "save_wordmap(wordmap)\n",
    "\n",
    "path_img = \"./data/highway/sun_bebjsikreyhhhefp.jpg\"\n",
    "#path_img = \"./data/aquarium/sun_aztvjgubyrgvirup.jpg\"\n",
    "image = io.imread(path_img)\n",
    "plt.figure()\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = image.astype('float')/255\n",
    "wordmap = get_visual_words(image, dictionary)\n",
    "save_wordmap(wordmap)\n",
    "\n",
    "path_img = \"./data/highway/sun_akihkricraebyttv.jpg\"\n",
    "#path_img = \"./data/aquarium/sun_aztvjgubyrgvirup.jpg\"\n",
    "image = io.imread(path_img)\n",
    "plt.figure()\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = image.astype('float')/255\n",
    "wordmap = get_visual_words(image, dictionary)\n",
    "save_wordmap(wordmap)\n",
    "\n",
    "path_img = \"./data/highway/sun_aikloxuincjpmnby.jpg\"\n",
    "#path_img = \"./data/aquarium/sun_aztvjgubyrgvirup.jpg\"\n",
    "image = io.imread(path_img)\n",
    "plt.figure()\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = image.astype('float')/255\n",
    "wordmap = get_visual_words(image, dictionary)\n",
    "save_wordmap(wordmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89dfba2e-f870-403c-b311-086d7e884dfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'io' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-45bb3cbc7a7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./data/laundromat/sun_afrmdtnsnxzodzwq.jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#path_img = \"./data/aquarium/sun_aztvjgubyrgvirup.jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'equal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'io' is not defined"
     ]
    }
   ],
   "source": [
    "path_img = \"./data/laundromat/sun_afrmdtnsnxzodzwq.jpg\"\n",
    "#path_img = \"./data/aquarium/sun_aztvjgubyrgvirup.jpg\"\n",
    "image = io.imread(path_img)\n",
    "plt.figure()\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = image.astype('float')/255\n",
    "wordmap = get_visual_words(image, dictionary)\n",
    "save_wordmap(wordmap)\n",
    "\n",
    "path_img = \"./data/highway/sun_agfcebcyjimgbcvr.jpg\"\n",
    "#path_img = \"./data/aquarium/sun_aztvjgubyrgvirup.jpg\"\n",
    "image = io.imread(path_img)\n",
    "plt.figure()\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = image.astype('float')/255\n",
    "wordmap = get_visual_words(image, dictionary)\n",
    "save_wordmap(wordmap)\n",
    "\n",
    "path_img = \"./data/laundromat/sun_addinpsdbmiewyvc.jpg\"\n",
    "#path_img = \"./data/aquarium/sun_aztvjgubyrgvirup.jpg\"\n",
    "image = io.imread(path_img)\n",
    "plt.figure()\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = image.astype('float')/255\n",
    "wordmap = get_visual_words(image, dictionary)\n",
    "save_wordmap(wordmap)\n",
    "\n",
    "path_img = \"./data/highway/sun_bsqoowlelpxyjkyt.jpg\"\n",
    "#path_img = \"./data/aquarium/sun_aztvjgubyrgvirup.jpg\"\n",
    "image = io.imread(path_img)\n",
    "plt.figure()\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = image.astype('float')/255\n",
    "wordmap = get_visual_words(image, dictionary)\n",
    "save_wordmap(wordmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c38698ca-a773-4db7-b55a-5dbc2ae2e1fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'io' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9b5f3652013b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./data/kitchen/sun_aggjlwcdjsjcaemh.jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#path_img = \"./data/aquarium/sun_aztvjgubyrgvirup.jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'equal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'io' is not defined"
     ]
    }
   ],
   "source": [
    "path_img = \"./data/kitchen/sun_aggjlwcdjsjcaemh.jpg\"\n",
    "#path_img = \"./data/aquarium/sun_aztvjgubyrgvirup.jpg\"\n",
    "image = io.imread(path_img)\n",
    "plt.figure()\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = image.astype('float')/255\n",
    "wordmap = get_visual_words(image, dictionary)\n",
    "save_wordmap(wordmap)\n",
    "histo = get_feature_from_wordmap(wordmap, dict_size = 200)\n",
    "plt.figure()\n",
    "bin_edges = np.arange(200 + 1)\n",
    "plt.bar(bin_edges[:-1], histo, width = 1)\n",
    "plt.xlabel(\"Words in Dictionary (indices)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim(0, 200)\n",
    "plt.show()\n",
    "\n",
    "path_img = \"./data/aquarium/sun_ayoehnnyhnartpwz.jpg\"\n",
    "#path_img = \"./data/aquarium/sun_aztvjgubyrgvirup.jpg\"\n",
    "image = io.imread(path_img)\n",
    "plt.figure()\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = image.astype('float')/255\n",
    "wordmap = get_visual_words(image, dictionary)\n",
    "save_wordmap(wordmap)\n",
    "histo = get_feature_from_wordmap(wordmap, dict_size = 200)\n",
    "plt.figure()\n",
    "bin_edges = np.arange(200 + 1)\n",
    "plt.bar(bin_edges[:-1], histo, width = 1)\n",
    "plt.xlabel(\"Words in Dictionary (indices)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim(0, 200)\n",
    "plt.show()\n",
    "\n",
    "path_img = \"./data/laundromat/sun_aalvewxltowiudlw.jpg\"\n",
    "#path_img = \"./data/aquarium/sun_aztvjgubyrgvirup.jpg\"\n",
    "image = io.imread(path_img)\n",
    "plt.figure()\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = image.astype('float')/255\n",
    "wordmap = get_visual_words(image, dictionary)\n",
    "save_wordmap(wordmap)\n",
    "histo = get_feature_from_wordmap(wordmap, dict_size = 200)\n",
    "plt.figure()\n",
    "bin_edges = np.arange(200 + 1)\n",
    "plt.bar(bin_edges[:-1], histo, width = 1)\n",
    "plt.xlabel(\"Words in Dictionary (indices)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim(0, 200)\n",
    "plt.show()\n",
    "\n",
    "path_img = \"./data/windmill/sun_avgtzbktnevdkgsy.jpg\"\n",
    "#path_img = \"./data/aquarium/sun_aztvjgubyrgvirup.jpg\"\n",
    "image = io.imread(path_img)\n",
    "plt.figure()\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = image.astype('float')/255\n",
    "wordmap = get_visual_words(image, dictionary)\n",
    "save_wordmap(wordmap)\n",
    "histo = get_feature_from_wordmap(wordmap, dict_size = 200)\n",
    "plt.figure()\n",
    "bin_edges = np.arange(200 + 1)\n",
    "plt.bar(bin_edges[:-1], histo, width = 1)\n",
    "plt.xlabel(\"Words in Dictionary (indices)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim(0, 200)\n",
    "plt.show()\n",
    "\n",
    "path_img = \"./data/highway/sun_aikloxuincjpmnby.jpg\"\n",
    "#path_img = \"./data/aquarium/sun_aztvjgubyrgvirup.jpg\"\n",
    "image = io.imread(path_img)\n",
    "plt.figure()\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = image.astype('float')/255\n",
    "wordmap = get_visual_words(image, dictionary)\n",
    "save_wordmap(wordmap)\n",
    "histo = get_feature_from_wordmap(wordmap, dict_size = 200)\n",
    "plt.figure()\n",
    "bin_edges = np.arange(200 + 1)\n",
    "plt.bar(bin_edges[:-1], histo, width = 1)\n",
    "plt.xlabel(\"Words in Dictionary (indices)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim(0, 200)\n",
    "plt.show()\n",
    "\n",
    "path_img = \"./data/park/labelme_mpjuzxdlazrdgyq.jpg\"\n",
    "#path_img = \"./data/aquarium/sun_aztvjgubyrgvirup.jpg\"\n",
    "image = io.imread(path_img)\n",
    "plt.figure()\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = image.astype('float')/255\n",
    "wordmap = get_visual_words(image, dictionary)\n",
    "save_wordmap(wordmap)\n",
    "histo = get_feature_from_wordmap(wordmap, dict_size = 200)\n",
    "plt.figure()\n",
    "bin_edges = np.arange(200 + 1)\n",
    "plt.bar(bin_edges[:-1], histo, width = 1)\n",
    "plt.xlabel(\"Words in Dictionary (indices)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim(0, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc45a3-cec2-491a-aaae-63f457e1309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multichannel_conv2d(x,weight,bias):\n",
    "    '''\n",
    "    Performs multi-channel 2D convolution.\n",
    "\n",
    "    [input]\n",
    "    * x: numpy.ndarray of shape (H,W,input_dim)\n",
    "    * weight: numpy.ndarray of shape (output_dim,input_dim,kernel_size,kernel_size)\n",
    "    * bias: numpy.ndarray of shape (output_dim)\n",
    "\n",
    "    [output]\n",
    "    * feat: numpy.ndarray of shape (H,W,output_dim)\n",
    "    '''\n",
    "    h, w, input_dims = x.shape\n",
    "    output_dims = weight.shape[0]\n",
    "    final_res = np.zeros((h, w, output_dims))\n",
    "    '''\n",
    "    HINTS:\n",
    "    1.> for 2D convolution we need to use np.fliplr and np.flipud\n",
    "    2.> can use scipy.ndimage.convolve with the flipped kernel\n",
    "    3.> don't forget to add the bias\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    inter = np.zeros((h, w, input_dims))\n",
    "    # filter = np.zeros((weight.shape[2], weight.shape[3]))\n",
    "    for i in range(output_dims):\n",
    "        for j in range(input_dims):\n",
    "            filter = np.fliplr(np.flipud(weight[i,j,:,:]))\n",
    "            inter[:,:,j] = scipy.ndimage.convolve(x[:,:,j], filter, mode = \"constant\")\n",
    "        final_res[:,:,i] = np.sum(inter, axis = 2) + bias[i]    \n",
    "    # raise NotImplementedError()\n",
    "    return final_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
